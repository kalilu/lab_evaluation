{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation Lab\n",
    "\n",
    "Complete the exercises below to solidify your knowledge and understanding of supervised learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T06:08:06.502894Z",
     "start_time": "2020-05-16T06:08:06.495911Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the boston dataset using sklearn and get the datasets X and y containing the target and the rest of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T14:57:14.623542Z",
     "start_time": "2020-05-15T14:57:11.512482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_boston(return_X_y=True)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `MEDV` field represents the median value of owner-occupied homes (in $1000's) and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T15:02:37.917471Z",
     "start_time": "2020-05-15T15:02:37.902154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (404, 13)\n",
      "y_train shape is: (404,)\n",
      "X_test shape is: (102, 13)\n",
      "y_test shape is: (102,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8)\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'y_train shape is: {y_train.shape}')\n",
    "print(f'X_test shape is: {X_test.shape}')\n",
    "print(f'y_test shape is: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a `LinearRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T16:42:57.988220Z",
     "start_time": "2020-05-15T16:42:57.980243Z"
    }
   },
   "outputs": [],
   "source": [
    "boston_model = LinearRegression()\n",
    "res = boston_model.fit(X_train, y_train)\n",
    "y_train_pred = boston_model.predict(X_train)\n",
    "y_test_pred  = boston_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and print R-squared for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T16:30:21.783970Z",
     "start_time": "2020-05-15T16:30:21.777986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " R-squared train: 0.7344713118301535\n",
      " R-squared test:  0.7415084833209453\n"
     ]
    }
   ],
   "source": [
    "print(f' R-squared train: {r2_score(y_train, y_train_pred)}') \n",
    "print(f' R-squared test:  {r2_score(y_test, y_test_pred)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and print mean squared error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T16:49:50.128303Z",
     "start_time": "2020-05-15T16:49:50.122321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mean squared error train: 21.7835673193422\n",
      " Mean squared error test: 23.60481820529573\n"
     ]
    }
   ],
   "source": [
    "print(f' Mean squared error train: {mean_squared_error(y_train, y_train_pred)}') \n",
    "print(f' Mean squared error test: {mean_squared_error(y_test, y_test_pred)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and print mean absolute error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T16:49:51.921593Z",
     "start_time": "2020-05-15T16:49:51.916609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mean absolute error train: 3.2194859581705715\n",
      " Mean absolute error test: 3.4903147378744803\n"
     ]
    }
   ],
   "source": [
    "print(f' Mean absolute error train: {mean_absolute_error(y_train, y_train_pred)}') \n",
    "print(f' Mean absolute error test: {mean_absolute_error(y_test, y_test_pred)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-06T11:04:12.134381Z",
     "start_time": "2019-10-06T11:04:12.130110Z"
    }
   },
   "source": [
    "Load the iris dataset using sklearn and get the datasets X and y containing the target and the rest of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T16:52:58.652504Z",
     "start_time": "2020-05-15T16:52:58.630566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `class` field represents the type of flower and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T16:55:14.469412Z",
     "start_time": "2020-05-15T16:55:14.461471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (120, 4)\n",
      "y_train shape is: (120,)\n",
      "X_test shape is: (30, 4)\n",
      "y_test shape is: (30,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8)\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'y_train shape is: {y_train.shape}')\n",
    "print(f'X_test shape is: {X_test.shape}')\n",
    "print(f'y_test shape is: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a `LogisticRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T17:02:41.087277Z",
     "start_time": "2020-05-15T17:02:41.048476Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_model = LogisticRegression()\n",
    "res = iris_model.fit(X_train, y_train)\n",
    "y_train_pred = iris_model.predict(X_train)\n",
    "y_test_pred  = iris_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and print the accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T18:53:39.696475Z",
     "start_time": "2020-05-15T18:53:39.680855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score train: 0.9916666666666667\n",
      "Accuracy score test: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "confusion_train= confusion_matrix(y_train, y_train_pred)\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "confusion_test= confusion_matrix(y_test, y_test_pred)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Accuracy score train: {accuracy_train}')\n",
    "print(f'Accuracy score test: {accuracy_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and print the balanced accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T19:49:25.402994Z",
     "start_time": "2020-05-15T19:49:25.387372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score train: 0.9912280701754387\n",
      "Balanced accuracy score test: 0.9444444444444445\n"
     ]
    }
   ],
   "source": [
    "confusion_train= balanced_accuracy_score(y_train, y_train_pred)\n",
    "confusion_test= balanced_accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Balanced accuracy score train: {confusion_train}')\n",
    "print(f'Balanced accuracy score test: {confusion_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and print the precision score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T21:29:04.542651Z",
     "start_time": "2020-05-15T21:29:04.531679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score train: 0.9922480620155039\n",
      "Precision score test: 0.9333333333333332\n"
     ]
    }
   ],
   "source": [
    "precision_train= precision_score(y_train, y_train_pred, average='macro')\n",
    "precision_test= precision_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "print(f'Precision score train: {precision_train}')\n",
    "print(f'Precision score test: {precision_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and print the recall score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T21:31:21.001086Z",
     "start_time": "2020-05-15T21:31:20.992112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score train: 0.9912280701754387\n",
      "Recall score test: 0.9444444444444445\n"
     ]
    }
   ],
   "source": [
    "recall_train= recall_score(y_train, y_train_pred, average='macro')\n",
    "recall_test= recall_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "print(f'Recall score train: {recall_train}')\n",
    "print(f'Recall score test: {recall_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and print the F1 score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T21:33:25.985073Z",
     "start_time": "2020-05-15T21:33:25.974100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score train: 0.9916339869281044\n",
      "F1 score test: 0.9326599326599326\n"
     ]
    }
   ],
   "source": [
    "f1_train= f1_score(y_train, y_train_pred, average='macro')\n",
    "f1_test= f1_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "print(f'F1 score train: {f1_train}')\n",
    "print(f'F1 score test: {f1_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate confusion matrices for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T21:35:58.997575Z",
     "start_time": "2020-05-15T21:35:58.977918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[40  0  0]\n",
      " [ 0 37  1]\n",
      " [ 0  0 42]]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "confusion_train= confusion_matrix(y_train, y_train_pred)\n",
    "print(f'Confusion matrix train: \\n{confusion_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T21:38:24.969298Z",
     "start_time": "2020-05-15T21:38:24.963319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix _test: \n",
      "[[10  0  0]\n",
      " [ 0 10  2]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "confusion_test= confusion_matrix(y_test, y_test_pred)\n",
    "print(f'Confusion matrix _test: \\n{confusion_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: For each of the data sets in this lab, try training with some of the other models you have learned about, recalculate the evaluation metrics, and compare to determine which models perform best on each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T06:15:22.743618Z",
     "start_time": "2020-05-16T06:15:22.734671Z"
    }
   },
   "outputs": [],
   "source": [
    "def baseline_report(model, X_train, X_test, y_train, y_test, name):\n",
    "    strat_k_fold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy     = np.mean(cross_val_score(model, X_train, y_train, cv=strat_k_fold, scoring='accuracy'))\n",
    "    precision    = np.mean(cross_val_score(model, X_train, y_train, cv=strat_k_fold, scoring='precision', average='macro'))\n",
    "    recall       = np.mean(cross_val_score(model, X_train, y_train, cv=strat_k_fold, scoring='recall', average='macro'))\n",
    "    f1score      = np.mean(cross_val_score(model, X_train, y_train, cv=strat_k_fold, scoring='f1'))\n",
    "    rocauc       = np.mean(cross_val_score(model, X_train, y_train, cv=strat_k_fold, scoring='roc_auc'))\n",
    "    y_pred = model.predict(X_test)\n",
    "    logloss      = log_loss(y_test, y_pred)   # SVC & LinearSVC unable to use cvs\n",
    "\n",
    "    df_model = pd.DataFrame({'model'        : [name],\n",
    "                             'accuracy'     : [accuracy],\n",
    "                             'precision'    : [precision],\n",
    "                             'recall'       : [recall],\n",
    "                             'f1score'      : [f1score],\n",
    "                             'rocauc'       : [rocauc],\n",
    "                             'logloss'      : [logloss]})   # timetaken: to be used for comparison later\n",
    "    return df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T06:16:40.502554Z",
     "start_time": "2020-05-16T06:16:39.842704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "X_train: (404, 13)\n",
      "y_train shape is: (404,)\n",
      "X_test shape is: (102, 13)\n",
      "y_test shape is: (102,)\n",
      " R-squared train: 1.0\n",
      " R-squared test:  -6.718019647832363\n",
      " Mean squared error train: 0.0\n",
      " Mean squared error test: 4482.745098039216\n",
      " Mean absolute error train: 0.0\n",
      " Mean absolute error test: 56.666666666666664\n"
     ]
    }
   ],
   "source": [
    "X, y = load_boston(return_X_y=True)\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8)\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_train = lab_enc.fit_transform(y_train)\n",
    "y_test = lab_enc.fit_transform(y_test)\n",
    "\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'y_train shape is: {y_train.shape}')\n",
    "print(f'X_test shape is: {X_test.shape}')\n",
    "print(f'y_test shape is: {y_test.shape}')\n",
    "\n",
    "boston_model = RandomForestClassifier()\n",
    "res = boston_model.fit(X_train, y_train)\n",
    "y_train_pred = boston_model.predict(X_train)\n",
    "y_test_pred  = boston_model.predict(X_test)\n",
    "\n",
    "print(f' R-squared train: {r2_score(y_train, y_train_pred)}') \n",
    "print(f' R-squared test:  {r2_score(y_test, y_test_pred)}') \n",
    "\n",
    "print(f' Mean squared error train: {mean_squared_error(y_train, y_train_pred)}') \n",
    "print(f' Mean squared error test: {mean_squared_error(y_test, y_test_pred)}') \n",
    "\n",
    "print(f' Mean absolute error train: {mean_absolute_error(y_train, y_train_pred)}') \n",
    "print(f' Mean absolute error test: {mean_absolute_error(y_test, y_test_pred)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T06:19:05.996681Z",
     "start_time": "2020-05-16T06:19:05.806179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "X_train: (120, 4)\n",
      "y_train shape is: (120,)\n",
      "X_test shape is: (30, 4)\n",
      "y_test shape is: (30,)\n",
      "Accuracy score train: 1.0\n",
      "Accuracy score test: 0.9333333333333333\n",
      "Balanced accuracy score train: 1.0\n",
      "Balanced accuracy score test: 0.9296296296296296\n",
      "Precision score train: 1.0\n",
      "Precision score test: 0.9296296296296296\n",
      "Recall score train: 1.0\n",
      "Recall score test: 0.9296296296296296\n",
      "F1 score train: 1.0\n",
      "F1 score test: 0.9296296296296296\n",
      "Confusion matrix train: \n",
      "[[39  0  0]\n",
      " [ 0 41  0]\n",
      " [ 0  0 40]]\n",
      "Confusion matrix _test: \n",
      "[[11  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  1  9]]\n"
     ]
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "print(X.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8)\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'y_train shape is: {y_train.shape}')\n",
    "print(f'X_test shape is: {X_test.shape}')\n",
    "print(f'y_test shape is: {y_test.shape}')\n",
    "iris_model = RandomForestClassifier()\n",
    "res = iris_model.fit(X_train, y_train)\n",
    "y_train_pred = iris_model.predict(X_train)\n",
    "y_test_pred  = iris_model.predict(X_test)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "print(f'Accuracy score train: {accuracy_train}')\n",
    "print(f'Accuracy score test: {accuracy_test}')\n",
    "\n",
    "confusion_train= balanced_accuracy_score(y_train, y_train_pred)\n",
    "confusion_test= balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f'Balanced accuracy score train: {confusion_train}')\n",
    "print(f'Balanced accuracy score test: {confusion_test}')\n",
    "\n",
    "precision_train= precision_score(y_train, y_train_pred, average='macro')\n",
    "precision_test= precision_score(y_test, y_test_pred, average='macro')\n",
    "print(f'Precision score train: {precision_train}')\n",
    "print(f'Precision score test: {precision_test}')\n",
    "\n",
    "recall_train= recall_score(y_train, y_train_pred, average='macro')\n",
    "recall_test= recall_score(y_test, y_test_pred, average='macro')\n",
    "print(f'Recall score train: {recall_train}')\n",
    "print(f'Recall score test: {recall_test}')\n",
    "\n",
    "f1_train= f1_score(y_train, y_train_pred, average='macro')\n",
    "f1_test= f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f'F1 score train: {f1_train}')\n",
    "print(f'F1 score test: {f1_test}')\n",
    "\n",
    "confusion_train= confusion_matrix(y_train, y_train_pred)\n",
    "print(f'Confusion matrix train: \\n{confusion_train}')\n",
    "confusion_test= confusion_matrix(y_test, y_test_pred)\n",
    "print(f'Confusion matrix _test: \\n{confusion_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
